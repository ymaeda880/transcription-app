# ------------------------------------------------------------
# ğŸ™ï¸ è©±è€…åˆ†é›¢ãƒ»æ•´å½¢ï¼ˆè­°äº‹éŒ²ã®å‰å‡¦ç†ï¼‰
# - .txt ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ— or è²¼ã‚Šä»˜ã‘
# - LLMã§è©±è€…æ¨å®šï¼ˆS1/S2/...ï¼‰ï¼‹ç™ºè©±ã”ã¨ã«æ”¹è¡Œãƒ»æ•´å½¢
# - GPT-5 ç³»åˆ—ã¯ temperature ã‚’å¤‰æ›´ä¸å¯ï¼ˆ=1å›ºå®šï¼‰â†’ UI ç„¡åŠ¹åŒ–ï¼†APIæœªé€ä¿¡
# - é•·æ–‡ï¼ˆ~2ä¸‡æ–‡å­—ï¼‰å¯¾å¿œï¼šmax_completion_tokens ã‚’ 10000 ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
# - ç©ºå¿œç­”æ™‚ã¯ resp å…¨ä½“ã‚’ st.json ã§å‡ºã—ã¦ãƒ‡ãƒãƒƒã‚°
# - finish_reason=="length" ã®ã¨ãã¯è‡ªå‹•ã§ max_completion_tokens ã‚’å¢—æ ã—ã¦å†å®Ÿè¡Œ
# - âœ… æ–™é‡‘è¨ˆç®—: lib.costs.estimate_chat_cost_usdï¼ˆconfig.MODEL_PRICES_USD å‚ç…§ï¼‰
# - âœ… ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—: lib.tokens.extract_tokens_from_responseï¼ˆpolicy é¸æŠå¯ï¼‰
# - âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†: lib/prompts.py ã®ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«çµ±ä¸€
# ------------------------------------------------------------
from __future__ import annotations

import time
from typing import Dict, Any

import streamlit as st
from openai import OpenAI

# ==== å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ====
from lib.costs import estimate_chat_cost_usd
from lib.tokens import extract_tokens_from_response, debug_usage_snapshot  # â† è¿½åŠ 
from lib.prompts import SPEAKER_PREP, get_group, build_prompt
from config.config import DEFAULT_USDJPY
from config.config import MAX_COMPLETION_BY_MODEL
from ui.style import disable_heading_anchors

# ========================== å…±é€šè¨­å®š ==========================
st.set_page_config(page_title="â‘¢ è©±è€…åˆ†é›¢ãƒ»æ•´å½¢ï¼ˆæ–°ï¼‰", page_icon="ğŸ™ï¸", layout="wide")
disable_heading_anchors()
st.title("â‘¢ è©±è€…åˆ†é›¢ãƒ»æ•´å½¢ï¼ˆæ–°ï¼‰â€” è­°äº‹éŒ²ã®å‰å‡¦ç†")

OPENAI_API_KEY = st.secrets.get("openai", {}).get("api_key") or st.secrets.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("OpenAI API Key ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.streamlit/secrets.toml ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# ========================== ãƒ¢ãƒ‡ãƒ«è¨­å®šè£œåŠ© ==========================
def supports_temperature(model_name: str) -> bool:
    """GPT-5ç³»ã¯ temperature å¤‰æ›´ä¸å¯ï¼ˆ=1å›ºå®šï¼‰ã€‚"""
    return not model_name.startswith("gpt-5")

# ========================== UI ==========================
left, right = st.columns([1, 1], gap="large")

# ---- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»UIï¼ˆlib/prompts ãƒ¬ã‚¸ã‚¹ãƒˆãƒªçµŒç”±ï¼‰ ----
with left:
    st.subheader("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")

    group = get_group(SPEAKER_PREP)

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
    if "mandatory_prompt" not in st.session_state:
        st.session_state["mandatory_prompt"] = group.mandatory_default
    if "preset_label" not in st.session_state:
        st.session_state["preset_label"] = group.label_for_key(group.default_preset_key)
    if "preset_text" not in st.session_state:
        st.session_state["preset_text"] = group.body_for_label(st.session_state["preset_label"])
    if "extra_text" not in st.session_state:
        st.session_state["extra_text"] = ""

    mandatory = st.text_area(
        "å¿…ãšå…¥ã‚‹éƒ¨åˆ†ï¼ˆå¸¸ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…ˆé ­ã«å«ã¾ã‚Œã¾ã™ï¼‰",
        height=220,
        key="mandatory_prompt",
    )

    def _on_change_preset():
        st.session_state["preset_text"] = group.body_for_label(st.session_state["preset_label"])

    st.selectbox(
        "è¿½è¨˜ãƒ—ãƒªã‚»ãƒƒãƒˆ",
        options=group.preset_labels(),
        index=group.preset_labels().index(st.session_state["preset_label"]),
        key="preset_label",
        help="é¸ã‚“ã å†…å®¹ãŒä¸Šã®å¿…é ˆæ–‡ã®ä¸‹ã«è‡ªå‹•çš„ã«é€£çµã•ã‚Œã¾ã™ã€‚",
        on_change=_on_change_preset,
    )

    preset_text = st.text_area("ï¼ˆç·¨é›†å¯ï¼‰ãƒ—ãƒªã‚»ãƒƒãƒˆæœ¬æ–‡", height=120, key="preset_text")
    extra = st.text_area("è¿½åŠ æŒ‡ç¤ºï¼ˆä»»æ„ï¼‰", height=88, key="extra_text")

    st.subheader("ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    model = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«",
        [
            "gpt-5",
            "gpt-5-mini",
            "gpt-5-nano",
            "gpt-4o-mini",
            "gpt-4o",
            "gpt-4.1-mini",
            "gpt-4.1",
            "gpt-3.5-turbo",
        ],
        index=1,
    )

    temp_supported = supports_temperature(model)
    temperature = st.slider(
        "æ¸©åº¦ï¼ˆ0=å³æ ¼ / 2=è‡ªç”±ï¼‰",
        0.0, 2.0, value=1.0, step=0.1,
        disabled=not temp_supported,
        help="GPT-5 ç³»åˆ—ã¯ temperature=1 å›ºå®šã§ã™",
    )
    if not temp_supported:
        st.caption("â„¹ï¸ GPT-5 ç³»åˆ—ã¯ temperature ã‚’å¤‰æ›´ã§ãã¾ã›ã‚“ï¼ˆ=1å›ºå®šï¼‰")

    default_max = MAX_COMPLETION_BY_MODEL.get(model, 10000)
    max_completion_tokens = st.number_input(
        "max_completion_tokensï¼ˆå‡ºåŠ›ä¸Šé™ï¼‰",
        min_value=256, max_value=128000, value=default_max, step=512,
        help="2ä¸‡æ–‡å­—ãªã‚‰ 8000ã€œ10000 æ¨å¥¨ã€‚finish_reason=length ã®å ´åˆã¯è‡ªå‹•ã§å¢—æ ã—ã¾ã™ã€‚",
    )

    # â˜… æ–™é‡‘è¨ˆç®—å‘ã‘ï¼šãƒˆãƒ¼ã‚¯ãƒ³ç®—å®šãƒãƒªã‚·ãƒ¼
    st.subheader("ãƒˆãƒ¼ã‚¯ãƒ³ç®—å®šãƒãƒªã‚·ãƒ¼ï¼ˆæ–™é‡‘è¨ˆç®—ç”¨ï¼‰")
    policy = st.selectbox(
        "policy",
        options=["billing", "prefer_completion", "prefer_output", "auto"],
        index=0,
        help=(
            "billing: å…¥åŠ›=input_tokenså„ªå…ˆ/å‡ºåŠ›=completion_tokenså„ªå…ˆï¼ˆæ¨å¥¨ï¼‰\n"
            "prefer_completion: æ—§APIã«è¿‘ã„æ„Ÿè¦šï¼ˆå‡ºåŠ›=completionå„ªå…ˆï¼‰\n"
            "prefer_output: modernã®å®šç¾©ã«å¿ å®Ÿï¼ˆå‡ºåŠ›=outputå„ªå…ˆï¼‰\n"
            "auto: modernå„ªå…ˆâ†’legacyã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
        ),
    )

    st.subheader("é€šè²¨æ›ç®—ï¼ˆä»»æ„ï¼‰")
    usd_jpy = st.number_input("USD/JPY", min_value=50.0, max_value=500.0, value=float(DEFAULT_USDJPY), step=0.5)

    c1, c2 = st.columns(2)
    run_btn = c1.button("è©±è€…åˆ†é›¢ã—ã¦æ•´å½¢", type="primary", use_container_width=True)
    push_btn = c2.button("â• ã“ã®çµæœã‚’ã€â‘¡ è­°äº‹éŒ²ä½œæˆã€ã¸æ¸¡ã™", use_container_width=True)

with right:
    st.subheader("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ")
    up = st.file_uploader("æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ.txtï¼‰ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", type=["txt"], accept_multiple_files=False)
    if up is not None:
        raw = up.read()
        try:
            text_from_file = raw.decode("utf-8")
        except UnicodeDecodeError:
            try:
                text_from_file = raw.decode("cp932")
            except Exception:
                text_from_file = raw.decode(errors="ignore")
        st.session_state["prep_source_text"] = text_from_file

    if "minutes_source_text" not in st.session_state:
        st.session_state["minutes_source_text"] = ""

    src = st.text_area(
        "æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆï¼ˆè²¼ã‚Šä»˜ã‘å¯ï¼‰",
        value=st.session_state.get("prep_source_text", st.session_state.get("minutes_source_text", "")),
        height=420,
        placeholder="â‘ ãƒšãƒ¼ã‚¸ã®çµæœã‚’å¼•ãç¶™ãã‹ã€ã“ã“ã«è²¼ã‚Šä»˜ã‘ã‚‹ã‹ã€.txt ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚",
    )

# ========================== å®Ÿè¡Œ ==========================
if run_btn:
    if not src.strip():
        st.warning("æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ„ã¿ç«‹ã¦
        combined = build_prompt(
            st.session_state["mandatory_prompt"],
            st.session_state["preset_text"],
            st.session_state["extra_text"],
            src,
        )

        def call_once(prompt_text: str, out_tokens: int):
            chat_kwargs: Dict[str, Any] = dict(
                model=model,
                messages=[{"role": "user", "content": prompt_text}],
                max_completion_tokens=int(out_tokens),
            )
            # GPT-5ç³»ã¯æ¸©åº¦å›ºå®šãªã®ã§é€ã‚‰ãªã„ã€‚ãã‚Œä»¥å¤–ã§1.0ã¨é•ã†æ™‚ã®ã¿é€ã‚‹ã€‚
            if supports_temperature(model) and abs(temperature - 1.0) > 1e-9:
                chat_kwargs["temperature"] = float(temperature)
            return client.chat.completions.create(**chat_kwargs)

        t0 = time.perf_counter()
        with st.spinner("è©±è€…åˆ†é›¢ãƒ»æ•´å½¢ã‚’å®Ÿè¡Œä¸­â€¦"):
            resp = call_once(combined, max_completion_tokens)

            text = ""
            finish_reason = None
            if resp and getattr(resp, "choices", None):
                try:
                    text = resp.choices[0].message.content or ""
                except Exception:
                    text = getattr(resp.choices[0], "text", "")
                try:
                    finish_reason = resp.choices[0].finish_reason
                except Exception:
                    finish_reason = None

            # è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤: å‡ºåŠ›ä¸è¶³ãªã‚‰å¢—æ 
            if (not text.strip()) or (finish_reason == "length"):
                bumped = int(min(max_completion_tokens * 1.5, 12000))
                if bumped > max_completion_tokens:
                    st.info(f"max_completion_tokens ã‚’ {max_completion_tokens} â†’ {bumped} ã«å¢—ã‚„ã—ã¦å†å®Ÿè¡Œã—ã¾ã™ã€‚")
                    resp = call_once(combined, bumped)
                    try:
                        text = resp.choices[0].message.content or ""
                    except Exception:
                        text = getattr(resp.choices[0], "text", "")

        elapsed = time.perf_counter() - t0

        if text.strip():
            st.markdown("### âœ… æ•´å½¢çµæœ")
            st.markdown(text)

            # === è¿½åŠ : ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ & ã‚³ãƒ”ãƒ¼ ===
            import json
            base_filename = "speaker_prep_result"
            txt_bytes = text.encode("utf-8")

            dl_col, cp_col = st.columns([1, 1], gap="small")
            with dl_col:
                st.download_button(
                    "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ.txtï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=txt_bytes,
                    file_name=f"{base_filename}.txt",
                    mime="text/plain",
                    use_container_width=True,
                )
            with cp_col:
                # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‚³ãƒ”ãƒ¼ï¼ˆClipboard APIï¼‰
                safe_json = json.dumps(text or "", ensure_ascii=False)
                st.components.v1.html(f"""
                <div style="display:flex;align-items:center;gap:.5rem">
                  <button id="copyBtn" style="width:100%;padding:.6rem 1rem;border-radius:.5rem;border:1px solid #e0e0e0;cursor:pointer">
                    ğŸ“‹ ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼
                  </button>
                  <span id="copyMsg" style="font-size:.9rem;color:#888"></span>
                </div>
                <script>
                  const content = {safe_json};
                  const btn = document.getElementById("copyBtn");
                  const msg = document.getElementById("copyMsg");
                  btn.addEventListener("click", async () => {{
                    try {{
                      await navigator.clipboard.writeText(content);
                      msg.textContent = "ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ";
                      setTimeout(() => msg.textContent = "", 1600);
                    }} catch (e) {{
                      msg.textContent = "ã‚³ãƒ”ãƒ¼ã«å¤±æ•—";
                      setTimeout(() => msg.textContent = "", 1600);
                    }}
                  }});
                </script>
                """, height=60)
            # === è¿½åŠ ã“ã“ã¾ã§ ===

        else:
            st.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç©ºã®å¿œç­”ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
            try:
                st.json(resp.model_dump())
            except Exception:
                st.write(resp)

        # === ãƒˆãƒ¼ã‚¯ãƒ³ç®—å‡ºï¼ˆæ–™é‡‘è¨ˆç®—å‘ã‘ policy ã‚’é©ç”¨ï¼‰ ===
        ptok, ctok, ttot = extract_tokens_from_response(resp, policy=policy)

        # æ–™é‡‘è¦‹ç©ã‚Š
        usd = estimate_chat_cost_usd(model, ptok, ctok)
        jpy = (usd * usd_jpy) if usd is not None else None

        import pandas as pd

        # ã¾ã¨ã‚ã¦è¡¨ã«ã™ã‚‹
        metrics_data = {
            "å‡¦ç†æ™‚é–“": [f"{elapsed:.2f} ç§’"],
            "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³": [f"{ptok:,}"],
            "å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³": [f"{ctok:,}"],
            "åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³": [f"{ttot:,}"],
            "æ¦‚ç®— (USD/JPY)": [f"${usd:,.6f} / Â¥{jpy:,.2f}" if usd is not None else "â€”"],
        }
        df_metrics = pd.DataFrame(metrics_data)
        st.subheader("ãƒˆãƒ¼ã‚¯ãƒ³ã¨æ–™é‡‘ã®æ¦‚è¦")
        st.table(df_metrics)   # é™çš„è¡¨ï¼ˆã‚³ãƒ”ãƒ¼ã—ã‚„ã™ã„ï¼‰
        # st.dataframe(df_metrics)  # â†ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ã—ãŸã„ãªã‚‰ã“ã¡ã‚‰

        # === ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šRAW usage ã‚’ç¢ºèª ===
        with st.expander("ğŸ” ãƒˆãƒ¼ã‚¯ãƒ³ç®—å‡ºã®å†…è¨³ï¼ˆRAW usage ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼‰"):
            try:
                st.write(debug_usage_snapshot(getattr(resp, "usage", None)))
            except Exception as e:
                st.write({"error": str(e)})

        st.session_state["prep_last_output"] = text
        st.session_state["minutes_source_text"] = text

# ========================== å¼•ãæ¸¡ã— ==========================
if push_btn:
    out = st.session_state.get("prep_last_output") or st.session_state.get("minutes_source_text", "")
    if not out.strip():
        st.warning("å…ˆã«ã€è©±è€…åˆ†é›¢ã—ã¦æ•´å½¢ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        st.session_state["minutes_source_text"] = out
        st.success("æ•´å½¢çµæœã‚’ã€â‘¡ è­°äº‹éŒ²ä½œæˆã€ãƒšãƒ¼ã‚¸ã¸æ¸¡ã—ã¾ã—ãŸã€‚å·¦ã®ãƒŠãƒ“ã‹ã‚‰ç§»å‹•ã—ã¦ãã ã•ã„ã€‚")

# ========================== ãƒ˜ãƒ«ãƒ— ==========================
with st.expander("âš ï¸ é•·æ–‡å…¥åŠ›ï¼ˆ2ä¸‡æ–‡å­—å‰å¾Œï¼‰ã®æ³¨æ„ç‚¹"):
    st.markdown(
        """
- æ—¥æœ¬èª2ä¸‡æ–‡å­—ã¯ **ç´„1ä¸‡ã€œ1.5ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³**ã§ã™ã€‚**gpt-4.1 / gpt-4o / gpt-5 ç³»**ï¼ˆ128kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰æ¨å¥¨ã€‚
- **max_completion_tokens** ã¯ 8000ã€œ10000 ç¨‹åº¦ãŒå®‰å…¨ã§ã™ã€‚finish_reason=length ãªã‚‰è‡ªå‹•ã§å¢—æ ã—ã¾ã™ã€‚
- ä¾¡æ ¼è¡¨ã¯ `config.MODEL_PRICES_USD`ï¼ˆUSD/100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚’é‹ç”¨ä¾¡æ ¼ã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
"""
    )
